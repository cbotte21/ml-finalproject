{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a percentage of movies from dataset. (Get movies with most reviews first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 4221\n"
     ]
    }
   ],
   "source": [
    "# Program uses {percentageDatasetUsed} * total movies.\n",
    "percentageDatasetUsed = 0.05\n",
    "\n",
    "# Load the datasets\n",
    "ratings = pd.read_csv('dataset/ratings.csv')\n",
    "movies = pd.read_csv('dataset/movies.csv')\n",
    "\n",
    "# Get {percentageDatasetUsed} * total top movie ids (by rating count).\n",
    "movie_rating_counts = ratings['movieId'].value_counts()\n",
    "sorted_movies = movie_rating_counts.sort_values(ascending=False)\n",
    "top_movies = sorted_movies.head(int(len(sorted_movies) * percentageDatasetUsed)).index\n",
    "\n",
    "print(\"Number of movies:\", len(top_movies))\n",
    "\n",
    "# Ratings of top movies\n",
    "filtered_ratings = ratings[ratings['movieId'].isin(top_movies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix of user,movie to rating\n",
    "row = filtered_ratings['movieId'].astype('category').cat.codes\n",
    "col = filtered_ratings['userId'].astype('category').cat.codes\n",
    "data = filtered_ratings['rating']\n",
    "movie_user_sparse = csr_matrix((data, (row, col)))\n",
    "\n",
    "# Using movie to movie as cited by the paper. Compute movie similarities\n",
    "movie_similarity = cosine_similarity(movie_user_sparse)\n",
    "movie_similarity_df = pd.DataFrame(movie_similarity, index=filtered_ratings['movieId'].unique(), columns=filtered_ratings['movieId'].unique())\n",
    "\n",
    "# Use the movie similarity matrix to create a sparse matrix for training the KNN model\n",
    "row, col = np.tril_indices(movie_similarity_df.shape[0], -1)\n",
    "data = movie_similarity_df.values[row, col]\n",
    "movie_movie_sparse = csr_matrix((data, (row, col)), shape=movie_similarity_df.shape)\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = train_test_split(movie_movie_sparse, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed all nearest neighbors.\n"
     ]
    }
   ],
   "source": [
    "nearestNeighbors = 5  # Nearest neighbors to use\n",
    "knn = NearestNeighbors(n_neighbors=nearestNeighbors, metric='cosine')\n",
    "knn.fit(train_data)\n",
    "\n",
    "# Precompute all nearest neighbors\n",
    "distances, indices = knn.kneighbors(test_data, n_neighbors=nearestNeighbors)\n",
    "print(\"Computed all nearest neighbors.\")\n",
    "\n",
    "# Function to compute predicted ratings\n",
    "def compute_rating(movie_idx, user_idx, test_data, train_data, indices, distances):\n",
    "    actual_rating = test_data[movie_idx, user_idx]\n",
    "    neighbor_ratings = train_data[indices[movie_idx], user_idx].toarray().flatten()\n",
    "    \n",
    "    weights = 1 - distances[movie_idx]\n",
    "    weighted_sum = np.dot(weights, neighbor_ratings)\n",
    "    weight_sum = np.sum(weights)\n",
    "    \n",
    "    predicted_rating = weighted_sum / weight_sum if weight_sum > 0 else np.nan\n",
    "    return actual_rating, predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1707522 jobs\n",
      "Progress: 0.0%\n",
      "Progress: 10.0%\n",
      "Progress: 20.0%\n",
      "Progress: 30.0%\n",
      "Progress: 40.0%\n",
      "Progress: 50.0%\n",
      "Progress: 60.0%\n",
      "Progress: 70.0%\n",
      "Progress: 80.0%\n",
      "Progress: 90.0%\n",
      "Progress: 100.0%\n",
      "Finished all jobs\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "test_ratings = []\n",
    "predicted_ratings = []\n",
    "\n",
    "# Total number of non-zero entries to process\n",
    "total_entries = len(test_data.nonzero()[0])\n",
    "\n",
    "print(f\"Starting {total_entries} jobs\")\n",
    "# Using ThreadPoolExecutor to parallelize the loop\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Submit all jobs to the executor\n",
    "    futures = [\n",
    "        executor.submit(compute_rating, idx[0], idx[1], test_data, train_data, indices, distances)\n",
    "        for idx in zip(*test_data.nonzero())\n",
    "    ]\n",
    "    \n",
    "    # Track progress as the jobs complete\n",
    "    for i, future in enumerate(as_completed(futures)):\n",
    "        actual_rating, predicted_rating = future.result()\n",
    "        test_ratings.append(actual_rating)\n",
    "        predicted_ratings.append(predicted_rating)\n",
    "        \n",
    "        # Print progress every 10%\n",
    "        if i % (total_entries // 10) == 0:\n",
    "            print(f\"Progress: {i / total_entries * 100:.1f}%\")\n",
    "\n",
    "print(\"Finished all jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example ratings: (Normalized, divided by 10)\n",
      "Test Ratings (first 10): [0.8269452331552032, 0.6238289435111065, 1.3046013366517284, 0.34089876260169405, 0.5156106587243132, 1.7875491395906062, 0.4056263186682759, 1.5329827867156254, 0.17227400012384528, 1.3465491729853138]\n",
      "Predicted Ratings (first 10): [0.8073276098496143, 0.827635480136313, 1.1450037147847305, 0.3749235213072952, 0.8101412616847288, 1.617134199590223, 0.5694430031875054, 1.233461634187698, 0.2517301253303633, 1.2695644363325564]\n",
      "\n",
      "Mean Squared Error on the test set: 0.055374935023618475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Denormalize the ratings by multiplying by 10\n",
    "denormalized_test_ratings = [rating * 10 for rating in test_ratings]\n",
    "denormalized_predicted_ratings = [rating * 10 for rating in predicted_ratings]\n",
    "\n",
    "firstX = 10\n",
    "print(\"\\nExample ratings: (Normalized, divided by 10)\")\n",
    "print(f\"Test Ratings (first {firstX}):\", denormalized_test_ratings[:firstX])\n",
    "print(f\"Predicted Ratings (first {firstX}):\", denormalized_predicted_ratings[:firstX])\n",
    "\n",
    "# Calculate the MSE\n",
    "mse = mean_squared_error(denormalized_test_ratings, denormalized_predicted_ratings)\n",
    "print(f\"\\nMean Squared Error on the test set: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
