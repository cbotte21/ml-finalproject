{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526b0859-a4d6-4b7e-860b-e5784f5315d2",
   "metadata": {},
   "source": [
    "Assuming we have the \"results.txt\" which contains the results of bruteforce finding the \"best\" hyperparameters (this was done through running create_model in parallel), then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f9d9fa4-68ed-45ee-9aa9-9295af922f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vowpalwabbit\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import model_selection\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85cff76b-0075-4c93-a696-08c6c34b645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast \n",
    "# best_rmse = np.inf\n",
    "# best_hyperparams = None\n",
    "# with open(\"results.txt\", 'r') as file:\n",
    "#     lines = file.readlines()[:107550]\n",
    "#     for line in lines:\n",
    "#         parsed_data = ast.literal_eval(line.strip())\n",
    "#         rmse = parsed_data[0]\n",
    "#         if rmse < best_rmse:\n",
    "#             best_rmse = rmse\n",
    "#             best_hyperparams = parsed_data[1]\n",
    "# print(best_rmse, best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d1e60-2a37-4527-87c4-5cc45ad13cfc",
   "metadata": {},
   "source": [
    "For lines 0-20,000, we have that 0.9793287079032921 {'l2': 0.0001, 'lrate': 0.01, 'passes': 1, 'rank': 39} is our best values.  \n",
    "For lines 20k-40k, we have 0.9804566075675284 {'l2': 0.0001, 'lrate': 0.01, 'passes': 6, 'rank': 39}.  \n",
    "For lines 40k-60k, we have 0.9918920165609537 {'l2': 0.03727593720314938, 'lrate': 0.01, 'passes': 6, 'rank': 15}.  \n",
    "For lines 60k-80k, we have 1.468098975181335 {'l2': 1.0, 'lrate': 0.005005, 'passes': 18, 'rank': 39}.  \n",
    "For lines 80k-100k, we have 1.0849137448164488 {'l2': 1.0, 'lrate': 0.1, 'passes': 1, 'rank': 39}.  \n",
    "For lines 100k+, 1.973363177731362 {'l2': 5.17947467923121, 'lrate': 0.1, 'passes': 18, 'rank': 39}.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7aa81-45a3-4d04-9b91-76befe01eb03",
   "metadata": {},
   "source": [
    "So, even though these RMSE aren't the best obtainable, they were obtained using a much smaller dataset so that computation doesn't take too long (25k training, 25k validation). Even so, brute forcing through this took considerable computational time. We can see that our minimized RMSE is obtained through having l2 = 0.0001, learning rate = 0.01, passes = 1, and rank = 39, and it's noteworthy that even though we were varying our rank between 15-39, 39 usually gave the best performance, which supports the idea that allowing more space for latent features increases our performance. More testing would need to be done to determine at which point performance would begin to fall off for this particular dataset. Additionally, as the rank increases, the space the model takes up increases exponentially, so with the current computation further testing isn't feasible because of time and computational constraints. The variable \"passes\" is the number of times each training example was used during training. Now, we can train our main model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2a8d721-5d9c-4309-839b-d52635947e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import convert, split\n",
    "from model_selection import create_model\n",
    "\n",
    "folder = \"ml-32m/\"\n",
    "#Dropping the timestamp feature as we're aren't making use of it\n",
    "ratings = pd.read_csv(folder+\"ratings.csv\").drop(\"timestamp\", axis=1)\n",
    "df1, testing_df = split(ratings, training_size=0.75, randomstate=1) \n",
    "testing = convert(testing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a404487-aeb1-48b3-bb2d-876a80e0fe79",
   "metadata": {},
   "source": [
    "Note that running the code below creates a cache file on disk \"model.cache\" and that the \"create_model\" function takes approx. 30 minutes to train as there are 16m examples in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb276c1a-76e0-475d-8085-3b4ee02d850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9159200690969022\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\"rank\": 39, \"l2\": 0.0001, \"lrate\": 0.01, \"passes\": 1}\n",
    "training_df, validation_df = split(df1, training_size=0.75, randomstate=1)\n",
    "training = convert(training_df)\n",
    "validation = convert(validation_df) \n",
    "model, rmse, _ = create_model(hyperparams=hyperparams, train=training, validation_df=validation_df, validation=validation, r_model=True)\n",
    "model.save(\"model.vw\")\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a60e8b9-735a-4af3-a4a5-f834501eb8c1",
   "metadata": {},
   "source": [
    "Assuming that we have the model saved as \"model.vw\" we can call it and finally, check our predictions for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28e8942f-e755-4d8e-b1b8-14e8f2846e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9159833576032641\n"
     ]
    }
   ],
   "source": [
    "model = vowpalwabbit.Workspace(\"-i model.vw\")\n",
    "predictions = model_selection.pred(model, testing)\n",
    "test_rmse = np.sqrt(mean_squared_error(testing_df[\"rating\"], predictions))\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe3198-1428-494e-a0df-64e91bef51bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
